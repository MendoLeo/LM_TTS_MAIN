{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.interpolate import interp1d\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First approch (mms)- remove utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour calculer la variance du pitch dans chaque segment en utilisant pYIN\n",
    "def calculate_pitch_variance(audio, sr, frame_length=2048, hop_length=512):\n",
    "    # Estimer le pitch avec pYIN\n",
    "    pitches, voiced_flags, voiced_probs = librosa.pyin(audio, \n",
    "                                                       fmin=librosa.note_to_hz('C2'), \n",
    "                                                       fmax=librosa.note_to_hz('C7'),\n",
    "                                                       sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Récupérer les pitches valides (où la voix est détectée)\n",
    "    pitches_valid = pitches[~np.isnan(pitches)]\n",
    "    \n",
    "    # Calculer la variance des pitches valides\n",
    "    if len(pitches_valid) > 0:\n",
    "        return np.var(pitches_valid)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Fonction pour segmenter l'audio en fonction de la durée et calculer la variance du pitch\n",
    "def remove_high_variance_segments(audio, sr, threshold=0.1, segment_duration=5.0):\n",
    "    segment_samples = int(segment_duration * sr)\n",
    "    num_segments = len(audio) // segment_samples\n",
    "    \n",
    "    # Créer une liste pour garder les segments valides\n",
    "    valid_segments = []\n",
    "    \n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_samples\n",
    "        end_sample = (i + 1) * segment_samples\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        \n",
    "        # Calculer la variance du pitch pour le segment\n",
    "        variance = calculate_pitch_variance(segment, sr)\n",
    "        \n",
    "        # Si la variance du pitch est inférieure au seuil, garder le segment\n",
    "        if variance < threshold:\n",
    "            valid_segments.append(segment)\n",
    "    \n",
    "    # Combiner les segments valides\n",
    "    return np.concatenate(valid_segments)\n",
    "\n",
    "# Charger un fichier audio\n",
    "audio_file = \"your_audio_file.wav\"  # Remplacez par le chemin de votre fichier audio\n",
    "audio, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Définir le seuil de variance et la durée des segments (par exemple, 5 secondes)\n",
    "variance_threshold = 100.0  # Ajustez le seuil selon vos besoins\n",
    "segment_duration = 5.0  # Durée de chaque segment à analyser\n",
    "\n",
    "# Supprimer les segments avec une variance de pitch trop élevée\n",
    "clean_audio = remove_high_variance_segments(audio, sr, threshold=variance_threshold, segment_duration=segment_duration)\n",
    "\n",
    "# Sauvegarder l'audio filtré\n",
    "sf.write(\"cleaned_audio_py.wav\", clean_audio, sr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approch-2: supprimer uniquement les hautes variances frequence dans les sous trames(5s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour calculer le pitch avec pYIN et identifier les frames valides\n",
    "def detect_high_variance_segments(audio, sr, frame_length=2048, hop_length=512, threshold=100.0):\n",
    "    # Estimer le pitch avec pYIN\n",
    "    pitches, voiced_flags, voiced_probs = librosa.pyin(audio, \n",
    "                                                       fmin=librosa.note_to_hz('C2'), \n",
    "                                                       fmax=librosa.note_to_hz('C7'),\n",
    "                                                       sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Récupérer les frames valides (où la voix est présente)\n",
    "    valid_pitches = pitches[~np.isnan(pitches)]\n",
    "    \n",
    "    # Si pas assez de données valides, garder l'audio inchangé\n",
    "    if len(valid_pitches) == 0:\n",
    "        return audio\n",
    "    \n",
    "    # Calculer la variance des pitches\n",
    "    pitch_variance = np.var(valid_pitches)\n",
    "    \n",
    "    # Supprimer les frames si la variance dépasse le seuil\n",
    "    if pitch_variance > threshold:\n",
    "        # Remplacer la portion audio par du silence si la variance est trop haute\n",
    "        audio[:] = 0  # Mettre la portion à zéro (silencieux)\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Fonction pour traiter tout l'audio en segments et supprimer les fragments à haute variance\n",
    "def process_audio(audio, sr, threshold=100.0, segment_duration=5.0):\n",
    "    segment_samples = int(segment_duration * sr)\n",
    "    num_segments = len(audio) // segment_samples\n",
    "    \n",
    "    # Créer une liste pour garder les segments traités\n",
    "    processed_audio = np.array([])\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_samples\n",
    "        end_sample = (i + 1) * segment_samples\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        \n",
    "        # Traiter chaque segment pour supprimer les portions avec haute variance de pitch\n",
    "        processed_segment = detect_high_variance_segments(segment, sr, threshold=threshold)\n",
    "        \n",
    "        # Ajouter le segment traité à l'audio final\n",
    "        processed_audio = np.concatenate((processed_audio, processed_segment))\n",
    "    \n",
    "    return audio, processed_audio\n",
    "\n",
    "# Charger un fichier audio\n",
    "audio_file = \"your_audio_file.wav\"  # Remplacez par le chemin de votre fichier audio\n",
    "audio, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Définir le seuil de variance et la durée des segments\n",
    "variance_threshold = 100.0  # Ajustez selon vos besoins\n",
    "segment_duration = 5.0  # Durée de chaque segment à analyser\n",
    "\n",
    "# Supprimer les fragments à haute variance dans l'audio entier\n",
    "aud, clean_audio = process_audio(audio, sr, threshold=variance_threshold, segment_duration=segment_duration)\n",
    "\n",
    "# Sauvegarder l'audio filtré\n",
    "sf.write(\"cleaned_audio_high_variance_removed.wav\", clean_audio, sr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comparaison des audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Écouter le signal original :\")\n",
    "display(Audio(aud, rate=sr))\n",
    "\n",
    "print(\"Écouter le signal lissé (moyenne glissante) :\")\n",
    "display(Audio(clean_audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approch 3: lisser la trame audio avec les hautes variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fonction pour lisser les fragments à haute variance\n",
    "def smooth_high_variance_segments(audio, sr, frame_length=2048, hop_length=512, threshold=100.0):\n",
    "    # Estimer le pitch avec pYIN\n",
    "    pitches, voiced_flags, voiced_probs = librosa.pyin(audio, \n",
    "                                                       fmin=librosa.note_to_hz('C2'), \n",
    "                                                       fmax=librosa.note_to_hz('C7'),\n",
    "                                                       sr=sr, hop_length=hop_length)\n",
    "    \n",
    "    # Récupérer les frames valides (où la voix est présente)\n",
    "    valid_pitches = pitches[~np.isnan(pitches)]\n",
    "    \n",
    "    if len(valid_pitches) == 0:\n",
    "        return audio\n",
    "    \n",
    "    pitch_variance = np.var(valid_pitches)\n",
    "    \n",
    "    if pitch_variance > threshold:\n",
    "        # Si variance élevée, lisser la portion audio par interpolation linéaire\n",
    "        t = np.arange(len(audio))\n",
    "        valid_indices = np.where(~np.isnan(pitches))[0]\n",
    "        valid_audio = audio[valid_indices]\n",
    "        \n",
    "        # Appliquer une interpolation linéaire sur les fragments invalides\n",
    "        interpolator = interp1d(valid_indices, valid_audio, bounds_error=False, fill_value=\"extrapolate\")\n",
    "        smoothed_audio = interpolator(t)\n",
    "        \n",
    "        return smoothed_audio\n",
    "    \n",
    "    return audio\n",
    "\n",
    "# Fonction pour traiter tout l'audio en segments et lisser les fragments à haute variance\n",
    "def process_audio_smoothing(audio, sr, threshold=100.0, segment_duration=5.0):\n",
    "    segment_samples = int(segment_duration * sr)\n",
    "    num_segments = len(audio) // segment_samples\n",
    "    \n",
    "    processed_audio = np.array([])\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start_sample = i * segment_samples\n",
    "        end_sample = (i + 1) * segment_samples\n",
    "        segment = audio[start_sample:end_sample]\n",
    "        \n",
    "        processed_segment = smooth_high_variance_segments(segment, sr, threshold=threshold)\n",
    "        processed_audio = np.concatenate((processed_audio, processed_segment))\n",
    "    \n",
    "    return processed_audio\n",
    "\n",
    "# Charger un fichier audio\n",
    "audio_file = \"your_audio_file.wav\"\n",
    "audio, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "# Appliquer le lissage sur les fragments à haute variance\n",
    "variance_threshold = 100.0\n",
    "segment_duration = 5.0\n",
    "\n",
    "smoothed_audio = process_audio_smoothing(audio, sr, threshold=variance_threshold, segment_duration=segment_duration)\n",
    "\n",
    "# Sauvegarder l'audio lissé\n",
    "sf.write(\"smoothed_audio.wav\", smoothed_audio, sr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
